{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1db988de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import numpy as np\n",
    "import cv2\n",
    "import json\n",
    "import glob\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "import numpy as np \n",
    "from collections import namedtuple\n",
    "from pycocotools import mask as mask_utils\n",
    "from PIL import Image\n",
    "from scipy.spatial import Delaunay\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1daf3065",
   "metadata": {},
   "outputs": [],
   "source": [
    "from helpers_cal import *\n",
    "from helpers_masktransfer import *\n",
    "from helpers_analysis import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "811089e4",
   "metadata": {},
   "source": [
    "The path below can be adjusted based on different dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec585f8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# COLMAP Path\n",
    "colmap_scripts_path = \"/userdata/chung-yu.wei/colmap/scripts/python\"\n",
    "if colmap_scripts_path not in sys.path:\n",
    "    sys.path.append(colmap_scripts_path)\n",
    "\n",
    "# Core data Paths\n",
    "base_path = \"/userdata/chung-yu.wei/3DRealCar/data/2024_07_02_15_18_44\"\n",
    "sparse_model_path = os.path.join(base_path, \"colmap_processed/sparse/0\")\n",
    "rgb_images_path = os.path.join(base_path, \"colmap_processed/input\")\n",
    "masks_path = os.path.join(base_path, \"colmap_processed/masks/sam\")\n",
    "\n",
    "# Depth map path\n",
    "depth_maps_path = os.path.join(base_path, \"3dscanner_origin\")\n",
    "\n",
    "# json component path\n",
    "component_json_path = os.path.join(base_path, \"2Dto2D_maskmatching/2024_07_02_15_18_44.json\")\n",
    "\n",
    "import read_write_model\n",
    "cameras, images, points3D = read_write_model.read_model(path=sparse_model_path, ext=\".bin\")\n",
    "print(\"COLMAP model loaded successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9883d8d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 3. Create Mappings from Image ID to File Paths ---\n",
    "image_id_to_rgb_path = {}\n",
    "image_id_to_depth_path = {}\n",
    "image_id_to_mask_path = {}\n",
    "\n",
    "for img_id, img_data in images.items():\n",
    "    image_name = img_data.name\n",
    "    base_name, ext = os.path.splitext(image_name)\n",
    "    number_part = base_name.split('_')[-1]\n",
    "\n",
    "    # Map to RGB image path\n",
    "    rgb_path = os.path.join(rgb_images_path, image_name)\n",
    "    if os.path.exists(rgb_path):\n",
    "        image_id_to_rgb_path[img_id] = rgb_path\n",
    "        \n",
    "    # Map to depth map path\n",
    "    depth_filename = f\"depth_{number_part}.png\"\n",
    "    depth_path = os.path.join(depth_maps_path, depth_filename)\n",
    "    if os.path.exists(depth_path):\n",
    "        image_id_to_depth_path[img_id] = depth_path\n",
    "\n",
    "    # Map to general vehicle mask path\n",
    "    mask_path = os.path.join(masks_path, image_name)\n",
    "    if os.path.exists(mask_path):\n",
    "        image_id_to_mask_path[img_id] = mask_path\n",
    "\n",
    "print(f\"✅ Created path mappings for {len(image_id_to_rgb_path)} images.\")\n",
    "\n",
    "# --- 4. Find All Valid Image IDs ---\n",
    "# An image is valid if it has an RGB, Mask, and Depth file\n",
    "valid_image_ids = [\n",
    "    img_id for img_id, path in image_id_to_rgb_path.items()\n",
    "    if os.path.exists(path) and\n",
    "       os.path.exists(image_id_to_mask_path.get(img_id, '')) and\n",
    "       os.path.exists(image_id_to_depth_path.get(img_id, ''))\n",
    "]\n",
    "print(f\"✅ Found {len(valid_image_ids)} images with all required files (RGB, Mask, Depth).\")\n",
    "\n",
    "print(\"\\n--- Setup Complete ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6afc9d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the list of components you want to analyze\n",
    "target_components = [\n",
    "    \"bonnet\",\n",
    "    \"bumper_f/cover\",\n",
    "    \"windshield_f\",\n",
    "    \"headlamp_l_assy\",\n",
    "    \"mirror_l_assy\",\n",
    "    \"grille\",\n",
    "    \"door_fl_assy\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b965805e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Pre-processing: Indexing and sorting all views for each component ---\n",
    "# Load component data\n",
    "image_name_to_anns, cat_id_to_name = load_component_data(component_json_path)\n",
    "\n",
    "print(\"--- Pre-processing: Finding the best view for each component ---\")\n",
    "\n",
    "# Create a map: {component_name: [(area, image_id), ...]}\n",
    "component_area_map = {}\n",
    "\n",
    "# Create a reverse map to find image_id from normalized name\n",
    "normalized_name_to_id = {\n",
    "    os.path.splitext(os.path.basename(img.name))[0]: img_id\n",
    "    for img_id, img in images.items()\n",
    "}\n",
    "\n",
    "# Iterate through all annotated images\n",
    "for normalized_name, annotations in image_name_to_anns.items():\n",
    "    if normalized_name in normalized_name_to_id:\n",
    "        image_id = normalized_name_to_id[normalized_name]\n",
    "        for ann in annotations:\n",
    "            component_name = cat_id_to_name[ann['category_id']]\n",
    "            \n",
    "            # Decode mask and calculate area\n",
    "            mask = mask_utils.decode(ann['segmentation'])\n",
    "            area = np.sum(mask > 0)\n",
    "            \n",
    "            # Store the data\n",
    "            if component_name not in component_area_map:\n",
    "                component_area_map[component_name] = []\n",
    "            component_area_map[component_name].append((area, image_id))\n",
    "\n",
    "# Sort the lists for each component by area (largest first)\n",
    "for component_name in component_area_map:\n",
    "    component_area_map[component_name].sort(key=lambda x: x[0], reverse=True)\n",
    "\n",
    "print(\"Pre-processing complete. Stored best views for all components.\")\n",
    "\n",
    "print(\"--- Pre-processing: Indexing and sorting all views for each component ---\")\n",
    "component_to_views_map = {}\n",
    "for normalized_name, annotations in image_name_to_anns.items():\n",
    "    if normalized_name in normalized_name_to_id:\n",
    "        image_id = normalized_name_to_id[normalized_name]\n",
    "        for ann in annotations:\n",
    "            component_name = cat_id_to_name[ann['category_id']]\n",
    "            if component_name not in component_to_views_map:\n",
    "                component_to_views_map[component_name] = []\n",
    "            mask = mask_utils.decode(ann['segmentation'])\n",
    "            area = np.sum(mask > 0)\n",
    "            component_to_views_map[component_name].append((area, image_id))\n",
    "\n",
    "# Sort each list by area in descending order\n",
    "for name in component_to_views_map:\n",
    "    component_to_views_map[name].sort(key=lambda x: x[0], reverse=True)\n",
    "print(\"Pre-processing complete. Indexed and sorted all views\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea483fe1",
   "metadata": {},
   "source": [
    "The Quickest & Best version currently, depth_tolerance with 0.5 is the best for right now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e977f06a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transfer_mask_v5(\n",
    "    source_id, target_id, source_component_mask, component_name,\n",
    "    images, cameras, image_id_to_rgb_path, image_id_to_depth_path, image_id_to_mask_path,\n",
    "    subsample_step=9,\n",
    "    depth_tolerance=0.50,\n",
    "    kernel_size=11\n",
    "):\n",
    "    \"\"\"\n",
    "    V5 (\"Tuned & Filtered\"): A tunable version that also filters out\n",
    "    source masks that are too small, using a component-specific threshold.\n",
    "    \"\"\"\n",
    "    source_h, source_w, _ = cv2.imread(image_id_to_rgb_path[source_id]).shape\n",
    "    mask_area = np.sum(source_component_mask > 0)\n",
    "    image_area = source_h * source_w\n",
    "    \n",
    "    # --- Get the component-specific threshold and apply the filter ---\n",
    "    min_mask_ratio = get_mask_size_threshold(component_name)\n",
    "    if (mask_area / image_area) < min_mask_ratio:\n",
    "        print(f\"    -> Source mask is too small ({mask_area / image_area:.2%}), below threshold of {min_mask_ratio:.2%}. Skipping this view.\")\n",
    "        return None\n",
    "\n",
    "    # (The internal logic is the same as your v3_fast, but uses the new tunable parameters)\n",
    "    target_rgb_for_size = cv2.imread(image_id_to_rgb_path[target_id]); target_h, target_w, _ = target_rgb_for_size.shape\n",
    "    source_depth_map_raw = cv2.imread(image_id_to_depth_path[source_id], cv2.IMREAD_UNCHANGED)\n",
    "    inpaint_mask = np.where(source_depth_map_raw == 0, 255, 0).astype(np.uint8)\n",
    "    source_depth_map = cv2.inpaint(source_depth_map_raw, inpaint_mask, 3, cv2.INPAINT_NS)\n",
    "    source_depth_map = cv2.resize(source_depth_map, (source_w, source_h), interpolation=cv2.INTER_NEAREST)\n",
    "    subsampled_mask = source_component_mask[::subsample_step, ::subsample_step]\n",
    "    source_pixels_y_sub, source_pixels_x_sub = np.where(subsampled_mask > 0)\n",
    "    source_pixels_y = source_pixels_y_sub * subsample_step\n",
    "    source_pixels_x = source_pixels_x_sub * subsample_step\n",
    "    source_pixels = np.vstack((source_pixels_x, source_pixels_y)).T\n",
    "    source_image_model, source_camera_model = images[source_id], cameras[images[source_id].camera_id]\n",
    "    point_cloud_3d = []\n",
    "    for u, v in source_pixels:\n",
    "        depth, _ = get_depth_from_map(u, v, source_depth_map)\n",
    "        if depth:\n",
    "            p_3d = back_project_point(u, v, depth, source_camera_model, source_image_model)\n",
    "            if p_3d is not None: point_cloud_3d.append(p_3d)\n",
    "    if not point_cloud_3d: return None\n",
    "    point_cloud_3d = np.array(point_cloud_3d)\n",
    "    shape_type = classify_component_shape(component_name)\n",
    "    points_to_project = None\n",
    "    if shape_type == 'planar':\n",
    "        points_to_project = fit_plane_ransac(point_cloud_3d)\n",
    "    else:\n",
    "        if len(point_cloud_3d) < 4: return None\n",
    "        tri = Delaunay(point_cloud_3d)\n",
    "        points_to_project = point_cloud_3d[np.unique(tri.simplices)]\n",
    "    if points_to_project is None or len(points_to_project) == 0: return None\n",
    "    target_depth_map_raw = cv2.imread(image_id_to_depth_path[target_id], cv2.IMREAD_UNCHANGED)\n",
    "    if target_depth_map_raw is None: return None\n",
    "    target_depth_map = cv2.resize(target_depth_map_raw, (target_w, target_h), interpolation=cv2.INTER_NEAREST)\n",
    "    visibility_checked_mask = np.zeros((target_h, target_w), dtype=np.uint8)\n",
    "    target_image_model, target_camera_model = images[target_id], cameras[images[target_id].camera_id]\n",
    "    R_target, t_target = qvec2rotmat(target_image_model.qvec), target_image_model.tvec\n",
    "    for p_3d in points_to_project:\n",
    "        p_cam_target = R_target @ p_3d + t_target\n",
    "        z_projected = p_cam_target[2]\n",
    "        if z_projected > 0:\n",
    "            p_2d_target = project_point(p_3d, target_camera_model, target_image_model)\n",
    "            if p_2d_target:\n",
    "                u_t, v_t = int(round(p_2d_target[0])), int(round(p_2d_target[1]))\n",
    "                if 0 <= v_t < target_h and 0 <= u_t < target_w:\n",
    "                    z_ground_truth, _ = get_depth_from_map(u_t, v_t, target_depth_map)\n",
    "                    if z_ground_truth and z_projected <= (z_ground_truth + depth_tolerance):\n",
    "                        visibility_checked_mask[v_t, u_t] = 255\n",
    "    kernel = np.ones((kernel_size, kernel_size), np.uint8)\n",
    "    closed_mask = cv2.morphologyEx(visibility_checked_mask, cv2.MORPH_CLOSE, kernel, iterations=3)\n",
    "    target_vehicle_mask = cv2.imread(image_id_to_mask_path.get(target_id, ''), cv2.IMREAD_GRAYSCALE)\n",
    "    if target_vehicle_mask is not None:\n",
    "        if target_vehicle_mask.shape != (target_h, target_w):\n",
    "            target_vehicle_mask = cv2.resize(target_vehicle_mask, (target_w, target_h), interpolation=cv2.INTER_NEAREST)\n",
    "        return cv2.bitwise_and(closed_mask, target_vehicle_mask)\n",
    "    else:\n",
    "        return closed_mask"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68acd6e7",
   "metadata": {},
   "source": [
    "4 Manually selected degress source images, can be change with better one.\n",
    "Also the stored results path can be change to your own path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a904c20b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================================\n",
    "# =================== CONTROL PANEL ======================\n",
    "# ==========================================================\n",
    "main_output_dir = \"Dataset2_Final_Manual_Analysis\"\n",
    "results_file_path = os.path.join(main_output_dir, \"final_manual_results.json\")\n",
    "report_file_path = os.path.join(main_output_dir, \"final_manual_report.txt\")\n",
    "\n",
    "# --- Manually define the 4 source images ---\n",
    "manual_source_image_names = [\"frame_00066.jpg\", \"frame_00191.jpg\", \"frame_00261.jpg\", \"frame_00770.jpg\"]\n",
    "\n",
    "# Create a mapping from image name to image ID for easy lookup\n",
    "# This assumes the `images` dictionary is loaded and available at this point.\n",
    "name_to_id_map = {img.name: img_id for img_id, img in images.items()}\n",
    "manual_source_ids = [name_to_id_map[name] for name in manual_source_image_names if name in name_to_id_map]\n",
    "\n",
    "# Check if all manual images were found\n",
    "if len(manual_source_ids) != 4:\n",
    "    print(\"Warning: Could not find all 4 manually specified source images in the dataset!\")\n",
    "    print(f\"Found IDs: {manual_source_ids}\")\n",
    "\n",
    "# Analyze all available components from your dataset\n",
    "# You can change this to your specific list if needed, e.g., [\"bonnet\", \"bumper_f/cover\", ...]\n",
    "components_to_analyze = sorted(list(component_to_views_map.keys()))\n",
    "# ==========================================================\n",
    "\n",
    "# Create a 2x2 grid for the plots. `figsize` can be adjusted as needed.\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "fig.suptitle(\"Visualization of the Four Manual Source Images\", fontsize=20)\n",
    "\n",
    "# Flatten the 2x2 `axes` array to make it easy to loop through (axes[0], axes[1], ...)\n",
    "axes = axes.flatten()\n",
    "\n",
    "# Loop through each filename and its corresponding subplot axis\n",
    "for i, filename in enumerate(manual_source_image_names):\n",
    "    # Construct the full path to the image\n",
    "    image_path = os.path.join(rgb_images_path, filename)\n",
    "    \n",
    "    # Check if the file actually exists before trying to read it\n",
    "    if os.path.exists(image_path):\n",
    "        # Read the image using OpenCV\n",
    "        image = cv2.imread(image_path)\n",
    "        # Convert from BGR (OpenCV's default) to RGB (Matplotlib's format)\n",
    "        image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        # Display the image on the corresponding subplot\n",
    "        axes[i].imshow(image_rgb)\n",
    "        axes[i].set_title(filename, fontsize=14)\n",
    "    else:\n",
    "        # If the image is not found, display a message on the plot\n",
    "        axes[i].text(0.5, 0.5, f\"Image not found:\\n{filename}\", \n",
    "                     ha='center', va='center', color='red')\n",
    "        axes[i].set_title(filename, fontsize=14)\n",
    "\n",
    "    # Turn off the axis ticks and labels for a cleaner look\n",
    "    axes[i].axis('off')\n",
    "\n",
    "# Adjust layout to prevent titles from overlapping and display the plot\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.95]) # Adjust rect to make space for the suptitle\n",
    "plt.show()\n",
    "\n",
    "# Create a color map to assign a unique color to each component\n",
    "num_components = len(components_to_analyze)\n",
    "# Using 'gist_rainbow' colormap for a wide variety of distinct colors\n",
    "colors = plt.cm.get_cmap('gist_rainbow', num_components)\n",
    "\n",
    "# Create a 2x2 grid for the plots\n",
    "fig, axes = plt.subplots(2, 2, figsize=(24, 18))\n",
    "fig.suptitle(\"Ground Truth Masks on Source Images\", fontsize=24)\n",
    "axes = axes.flatten()\n",
    "\n",
    "# Loop through each of the four source images\n",
    "for i, filename in enumerate(manual_source_image_names):\n",
    "    ax = axes[i]\n",
    "    image_path = os.path.join(rgb_images_path, filename)\n",
    "    \n",
    "    if not os.path.exists(image_path):\n",
    "        ax.text(0.5, 0.5, f\"Image not found:\\n{filename}\", ha='center', va='center', color='red')\n",
    "        ax.set_title(filename)\n",
    "        ax.axis('off')\n",
    "        continue\n",
    "\n",
    "    # Read the image and create a copy to draw on\n",
    "    image_rgb = cv2.cvtColor(cv2.imread(image_path), cv2.COLOR_BGR2RGB)\n",
    "    overlay = image_rgb.copy()\n",
    "    h, w, _ = image_rgb.shape\n",
    "    \n",
    "    legend_patches = []\n",
    "\n",
    "    # Loop through all possible components to find their masks on this image\n",
    "    for j, component_name in enumerate(components_to_analyze):\n",
    "        mask, _ = get_component_mask_robust(filename, component_name, image_name_to_anns, cat_id_to_name, h, w)\n",
    "        \n",
    "        if mask is not None:\n",
    "            # Get the color for this component (RGBA format)\n",
    "            color = colors(j)\n",
    "            # Convert to RGB for blending (and scale from 0-1 to 0-255)\n",
    "            blend_color = np.array(color[:3]) * 255\n",
    "            \n",
    "            # Create the colored overlay for the mask\n",
    "            roi = overlay[mask > 0]\n",
    "            blended_roi = (roi * 0.5 + blend_color * 0.5).astype(np.uint8)\n",
    "            overlay[mask > 0] = blended_roi\n",
    "            \n",
    "            # Add this component to the legend\n",
    "            legend_patches.append(mpatches.Patch(color=color, label=component_name))\n",
    "\n",
    "    # Display the final image with all masks overlaid\n",
    "    ax.imshow(overlay)\n",
    "    ax.set_title(filename, fontsize=16)\n",
    "    ax.axis('off')\n",
    "    # Add the legend to the plot\n",
    "    if legend_patches:\n",
    "        ax.legend(handles=legend_patches, bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0.)\n",
    "\n",
    "# Adjust layout and display the plot\n",
    "plt.tight_layout(rect=[0, 0, 0.9, 0.95]) # Adjust rect for suptitle and legend\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "765f0c73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Load or initialize results ---\n",
    "if os.path.exists(results_file_path):\n",
    "    with open(results_file_path, 'r') as f:\n",
    "        all_results = json.load(f)\n",
    "else:\n",
    "    all_results = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d7878dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 1. Main Analysis Function (Modified to use manual sources) ---\n",
    "\n",
    "def run_component_miou_analysis(component_name, existing_results):\n",
    "    \"\"\"\n",
    "    Runs an exhaustive analysis for a component using the 4 manually selected source images.\n",
    "    \"\"\"\n",
    "    print(f\"\\n{'='*25}\\n--- Preparing Analysis for '{component_name}' ---\\n{'='*25}\")\n",
    "    \n",
    "    start_time_component = time.time()\n",
    "    \n",
    "    source_ids = manual_source_ids\n",
    "    print(f\"Using manually selected source images with IDs: {source_ids}\")\n",
    "\n",
    "\n",
    "    valid_targets = [tid for tid in valid_image_ids if tid not in source_ids and get_component_mask(images[tid].name, component_name, image_name_to_anns, cat_id_to_name)[0] is not None]\n",
    "    if not valid_targets:\n",
    "        print(f\"No valid target images with ground truth found for '{component_name}'. Skipping.\")\n",
    "        return None\n",
    "    \n",
    "    print(f\"Found {len(valid_targets)} valid targets to test against.\")\n",
    "    \n",
    "    component_results = existing_results.copy() # Use existing results to resume\n",
    "    \n",
    "    # Create a list of targets that still need to be analyzed\n",
    "    targets_to_run = [tid for tid in valid_targets if images[tid].name not in component_results]\n",
    "\n",
    "    # Use tqdm for a progress bar over the selected targets\n",
    "    for target_id in tqdm(targets_to_run, desc=f\"Analyzing {component_name}\"):\n",
    "        target_name = images[target_id].name\n",
    "        target_gt_mask, _ = get_component_mask(target_name, component_name, image_name_to_anns, cat_id_to_name)\n",
    "        \n",
    "        projected_masks = []\n",
    "        for sid in source_ids:\n",
    "            source_mask, _ = get_component_mask(images[sid].name, component_name, image_name_to_anns, cat_id_to_name)\n",
    "            if source_mask is not None:\n",
    "                transferred_mask = transfer_mask_v5(sid, target_id, source_mask, component_name, images, cameras, image_id_to_rgb_path, image_id_to_depth_path, image_id_to_mask_path)\n",
    "                if transferred_mask is not None:\n",
    "                    projected_masks.append(transferred_mask)\n",
    "        \n",
    "        if not projected_masks:\n",
    "            continue\n",
    "            \n",
    "        target_h, target_w, _ = cv2.imread(image_id_to_rgb_path[target_id]).shape\n",
    "        union_mask = np.zeros((target_h, target_w), dtype=np.uint8)\n",
    "        for mask in projected_masks:\n",
    "            union_mask = cv2.bitwise_or(union_mask, mask)\n",
    "        \n",
    "        iou_score = calculate_iou(union_mask, target_gt_mask)\n",
    "        \n",
    "        # Save progress for this specific target\n",
    "        component_results[target_name] = {\"iou\": iou_score}\n",
    "        all_results[component_name] = component_results\n",
    "        with open(results_file_path, 'w') as f:\n",
    "            json.dump(all_results, f, indent=4)\n",
    "\n",
    "    end_time_component = time.time()\n",
    "    total_time = end_time_component - start_time_component\n",
    "    \n",
    "    # Add summary stats to the results for this component\n",
    "    all_iou_scores = [res['iou'] for res in component_results.values()]\n",
    "    component_results[\"individual_scores\"] = all_iou_scores\n",
    "    component_results[\"avg_iou\"] = np.mean(all_iou_scores)\n",
    "    component_results[\"total_time\"] = total_time\n",
    "    component_results[\"combinations_tested\"] = len(all_iou_scores)\n",
    "\n",
    "    return component_results\n",
    "\n",
    "\n",
    "# --- Main Execution and Reporting Block ---\n",
    "\n",
    "os.makedirs(main_output_dir, exist_ok=True)\n",
    "if os.path.exists(results_file_path):\n",
    "    print(f\"Loading existing results from '{results_file_path}'...\")\n",
    "    with open(results_file_path, 'r') as f:\n",
    "        all_results = json.load(f)\n",
    "else:\n",
    "    print(\"No existing results file found. Starting a new analysis.\")\n",
    "    all_results = {}\n",
    "\n",
    "total_analysis_time = 0\n",
    "\n",
    "for component_name in components_to_analyze:\n",
    "    # --- Stage 1: Run the Analysis for the Component ---\n",
    "    if component_name not in all_results or \"avg_iou\" not in all_results[component_name]:\n",
    "        updated_results = run_component_miou_analysis(component_name, all_results.get(component_name, {}))\n",
    "        if updated_results:\n",
    "            all_results[component_name] = updated_results\n",
    "            total_analysis_time += updated_results.get(\"total_time\", 0)\n",
    "            with open(results_file_path, 'w') as f:\n",
    "                json.dump(all_results, f, indent=4)\n",
    "    else:\n",
    "        print(f\"\\nAnalysis for '{component_name}' already complete. Skipping computation.\")\n",
    "\n",
    "    # --- Stage 2: Generate and Save Visualization for the Component (Modified for Robustness) ---\n",
    "    print(f\"\\n--- Generating visualization for '{component_name}' ---\")\n",
    "\n",
    "    # Define the output directory for this component's visualization\n",
    "    component_output_dir = os.path.join(main_output_dir, component_name.replace('/', '_'))\n",
    "    \n",
    "    # Check if the directory exists and if there's already a PNG file in it\n",
    "    # Note: You need to have 'import glob' at the top of your script for this to work.\n",
    "    if os.path.isdir(component_output_dir) and glob.glob(os.path.join(component_output_dir, '*.png')):\n",
    "        print(f\"  - Visualization already exists for '{component_name}'. Skipping generation.\")\n",
    "        continue\n",
    "\n",
    "    if component_name in all_results and all_results[component_name]:\n",
    "        # Filter for actual target results, not summary keys\n",
    "        successful_targets = [t for t in all_results[component_name].keys() if isinstance(all_results[component_name][t], dict) and 'iou' in all_results[component_name][t]]\n",
    "        \n",
    "        if not successful_targets:\n",
    "            print(\"No successful targets to visualize for this component.\")\n",
    "            continue\n",
    "\n",
    "        target_name_to_viz = random.choice(successful_targets)\n",
    "        target_id_to_viz = next((img_id for img_id, img in images.items() if img.name == target_name_to_viz), None)\n",
    "        \n",
    "        if target_id_to_viz:\n",
    "            print(f\"  - Visualizing projection for target: {target_name_to_viz}\")\n",
    "            source_ids_viz = manual_source_ids\n",
    "            \n",
    "            projected_masks_viz = []\n",
    "            source_masks_viz = []\n",
    "            source_rgbs_viz = []\n",
    "\n",
    "            # Loop through all source IDs and handle missing data\n",
    "            for sid in source_ids_viz:\n",
    "                source_rgb = cv2.cvtColor(cv2.imread(image_id_to_rgb_path[sid]), cv2.COLOR_BGR2RGB)\n",
    "                source_h, source_w, _ = source_rgb.shape\n",
    "                source_rgbs_viz.append(source_rgb) # Always add the source image\n",
    "                \n",
    "                source_mask, _ = get_component_mask_robust(images[sid].name, component_name, image_name_to_anns, cat_id_to_name, source_h, source_w)\n",
    "                source_masks_viz.append(source_mask) # Add the mask (or None if not found)\n",
    "                \n",
    "                # Only attempt to project if we found a source mask\n",
    "                if source_mask is not None:\n",
    "                    transferred_mask = transfer_mask_v5(sid, target_id_to_viz, source_mask, component_name, images, cameras, image_id_to_rgb_path, image_id_to_depth_path, image_id_to_mask_path)\n",
    "                    projected_masks_viz.append(transferred_mask) # Add the result (or None if projection fails)\n",
    "                else:\n",
    "                    projected_masks_viz.append(None) # Add None if there was no mask to project\n",
    "            \n",
    "            # --- Create the detailed plot, now robust to missing masks ---\n",
    "            num_sources = len(source_ids_viz)\n",
    "            fig, axes = plt.subplots(3, num_sources, figsize=(10 * num_sources, 30))\n",
    "            fig.suptitle(f\"Detailed Visualization for '{component_name}' on {target_name_to_viz}\", fontsize=30, y=0.95)\n",
    "            target_rgb = cv2.cvtColor(cv2.imread(image_id_to_rgb_path[target_id_to_viz]), cv2.COLOR_BGR2RGB)\n",
    "\n",
    "            # Row 1: Source Masks\n",
    "            for j in range(num_sources):\n",
    "                ax = axes[0, j]\n",
    "                ax.imshow(source_rgbs_viz[j])\n",
    "                if source_masks_viz[j] is not None:\n",
    "                    ax.imshow(np.ma.masked_where(source_masks_viz[j] == 0, source_masks_viz[j]), cmap='cool', alpha=0.6)\n",
    "                    ax.set_title(f\"Source {chr(65+j)}\")\n",
    "                else:\n",
    "                    ax.set_title(f\"Source {chr(65+j)}\\n(Mask Not Found)\")\n",
    "                ax.axis('off')\n",
    "\n",
    "            # Row 2: Individual Projected Masks\n",
    "            for j in range(num_sources):\n",
    "                ax = axes[1, j]\n",
    "                ax.imshow(target_rgb)\n",
    "                if projected_masks_viz[j] is not None:\n",
    "                    ax.imshow(np.ma.masked_where(projected_masks_viz[j] == 0, projected_masks_viz[j]), cmap='plasma', alpha=0.6)\n",
    "                    ax.set_title(f\"Projection from Source {chr(65+j)}\")\n",
    "                else:\n",
    "                    ax.set_title(f\"Projection from Source {chr(65+j)}\\n(No Source or Failed Projection)\")\n",
    "                ax.axis('off')\n",
    "\n",
    "            # Row 3: Final Combined Results\n",
    "            valid_projected_masks = [m for m in projected_masks_viz if m is not None]\n",
    "            target_h, target_w, _ = target_rgb.shape\n",
    "            union_mask = np.zeros((target_h, target_w), dtype=np.uint8)\n",
    "            if valid_projected_masks:\n",
    "                for mask in valid_projected_masks:\n",
    "                    union_mask = cv2.bitwise_or(union_mask, mask)\n",
    "            \n",
    "            target_gt_mask, _ = get_component_mask_robust(target_name_to_viz, component_name, image_name_to_anns, cat_id_to_name, target_h, target_w)\n",
    "            iou_score = calculate_iou(union_mask, target_gt_mask) if target_gt_mask is not None else -1.0 # Handle missing GT\n",
    "            \n",
    "            # Plot Final Union\n",
    "            axes[2, 0].imshow(target_rgb)\n",
    "            axes[2, 0].imshow(np.ma.masked_where(union_mask == 0, union_mask), cmap='Greens', alpha=0.7)\n",
    "            axes[2, 0].set_title(f\"Final Union (IoU: {iou_score:.4f})\")\n",
    "            axes[2, 0].axis('off')\n",
    "            \n",
    "            # Plot Ground Truth\n",
    "            axes[2, 1].imshow(target_rgb)\n",
    "            if target_gt_mask is not None:\n",
    "                axes[2, 1].imshow(np.ma.masked_where(target_gt_mask == 0, target_gt_mask), cmap='YlOrRd', alpha=0.7)\n",
    "            axes[2, 1].set_title(\"Ground Truth\")\n",
    "            axes[2, 1].axis('off')\n",
    "            \n",
    "            # Turn off remaining axes in the last row\n",
    "            for j in range(2, num_sources):\n",
    "                axes[2, j].axis('off')\n",
    "\n",
    "            component_output_dir = os.path.join(main_output_dir, component_name.replace('/', '_'))\n",
    "            os.makedirs(component_output_dir, exist_ok=True)\n",
    "            save_path = os.path.join(component_output_dir, f\"visualization_{target_name_to_viz}.png\")\n",
    "            \n",
    "            plt.tight_layout(rect=[0, 0, 1, 0.93])\n",
    "            plt.savefig(save_path)\n",
    "            plt.close(fig)\n",
    "            print(f\"  - Visualization saved to '{save_path}'\")\n",
    "\n",
    "# --- 4. Final Consolidated Report ---\n",
    "print(\"\\n\\n\" + \"=\"*50)\n",
    "print(\"      FINAL MEAN IoU (mIoU) REPORT\")\n",
    "print(\"=\"*50)\n",
    "report_lines = []\n",
    "overall_iou_scores = []\n",
    "\n",
    "# Reload the most up-to-date results before printing the report\n",
    "with open(results_file_path, 'r') as f:\n",
    "    final_results_to_report = json.load(f)\n",
    "\n",
    "for component, data in sorted(final_results_to_report.items()):\n",
    "    if \"avg_iou\" in data:\n",
    "        report_lines.append(f\"\\n--- Component: '{component}' ---\")\n",
    "        report_lines.append(f\"  - Combinations Tested: {data['combinations_tested']}\")\n",
    "        report_lines.append(f\"  - Total Time for Component: {data['total_time']:.2f} seconds\")\n",
    "        report_lines.append(f\"  - Individual IoU Scores: {', '.join([f'{s:.4f}' for s in data['individual_scores']])}\")\n",
    "        report_lines.append(f\"  >>> Mean IoU (mIoU): {data['avg_iou']:.4f}\")\n",
    "        overall_iou_scores.extend(data['individual_scores'])\n",
    "\n",
    "if overall_iou_scores:\n",
    "    overall_miou = np.mean(overall_iou_scores)\n",
    "    report_lines.append(\"\\n\\n\" + \"=\"*50)\n",
    "    report_lines.append(\"      OVERALL SUMMARY\")\n",
    "    report_lines.append(\"=\"*50)\n",
    "    report_lines.append(f\"\\n- Total Number of Components Analyzed: {len(final_results_to_report)}\")\n",
    "    report_lines.append(f\"- Total Time for All New Analyses: {total_analysis_time:.2f} seconds\")\n",
    "    report_lines.append(f\">>> FINAL Overall mIoU across all components: {overall_miou:.4f} <<<\")\n",
    "\n",
    "final_report_string = \"\\n\".join(report_lines)\n",
    "with open(report_file_path, 'w') as f_out:\n",
    "    f_out.write(final_report_string)\n",
    "\n",
    "print(final_report_string)\n",
    "print(f\"\\n\\nAnalysis complete. Visualizations saved in '{main_output_dir}'. Full report saved to '{report_file_path}'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7b09850",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 1. Define the 3 Fixed Examples for Comparison ---\n",
    "try:\n",
    "    fixed_examples = [\n",
    "        {\n",
    "            \"component\": \"bonnet\",\n",
    "            \"source_id\": component_to_views_map[\"bonnet\"][0][1], # Best view\n",
    "            \"target_id\": component_to_views_map[\"bonnet\"][5][1]  # A different, good view\n",
    "        },\n",
    "        {\n",
    "            \"component\": \"windshield_f\",\n",
    "            \"source_id\": component_to_views_map[\"windshield_f\"][0][1], # Best view\n",
    "            \"target_id\": component_to_views_map[\"windshield_f\"][3][1]   # A different, good view\n",
    "        },\n",
    "        {\n",
    "            \"component\": \"bumper_f/cover\",\n",
    "            \"source_id\": component_to_views_map[\"bumper_f/cover\"][0][1], # Best view\n",
    "            \"target_id\": component_to_views_map[\"bumper_f/cover\"][7][1] # A different, good view\n",
    "        }\n",
    "    ]\n",
    "except (KeyError, IndexError):\n",
    "    print(\"Warning: Could not create fixed examples. Falling back to a single random example.\")\n",
    "    # Fallback to a single random example if the fixed ones aren't available\n",
    "    component_name = random.choice([\"bonnet\", \"bumper_f/cover\", \"windshield_f\"])\n",
    "    source_id = component_to_views_map.get(component_name, [])[0][1]\n",
    "    target_id = random.choice([i for i in valid_image_ids if i != source_id and get_component_mask_robust(images[i].name, component_name, image_name_to_anns, cat_id_to_name, images[i].height, images[i].width)[0] is not None])\n",
    "    fixed_examples = [{\"component\": component_name, \"source_id\": source_id, \"target_id\": target_id}]\n",
    "\n",
    "\n",
    "# --- 2. Main Execution Block (Modified) ---\n",
    "for i, example in enumerate(fixed_examples):\n",
    "    component_name = example[\"component\"]\n",
    "    source_id = example[\"source_id\"]\n",
    "    target_id = example[\"target_id\"]\n",
    "    \n",
    "    print(f\"\\n{'='*25}\\n--- Running Comparison Example {i+1} for '{component_name}' ---\\n{'='*25}\")\n",
    "    print(f\"  - Source: {images[source_id].name}\")\n",
    "    print(f\"  - Target: {images[target_id].name}\")\n",
    "\n",
    "    # --- Get Source and Target Masks ---\n",
    "    source_rgb = cv2.cvtColor(cv2.imread(image_id_to_rgb_path[source_id]), cv2.COLOR_BGR2RGB)\n",
    "    source_h, source_w, _ = source_rgb.shape\n",
    "    source_mask, _ = get_component_mask_robust(images[source_id].name, component_name, image_name_to_anns, cat_id_to_name, source_h, source_w)\n",
    "    \n",
    "    target_rgb = cv2.cvtColor(cv2.imread(image_id_to_rgb_path[target_id]), cv2.COLOR_BGR2RGB)\n",
    "    target_h, target_w, _ = target_rgb.shape\n",
    "    target_gt_mask, _ = get_component_mask_robust(images[target_id].name, component_name, image_name_to_anns, cat_id_to_name, target_h, target_w)\n",
    "\n",
    "    if source_mask is None or target_gt_mask is None:\n",
    "        print(\"Could not get a valid source or target mask for this example. Skipping.\")\n",
    "        continue\n",
    "\n",
    "    # --- Run All Transfer Methods, Calculate IoU, and Time ---\n",
    "    masks = {}\n",
    "    ious = {}\n",
    "    times = {}\n",
    "    \n",
    "    print(\"\\n--- Running Methods ---\")\n",
    "    \n",
    "    # V1\n",
    "    start_time = time.time(); masks['v1'] = transfer_mask_v1(source_id, target_id, source_mask, images, cameras, image_id_to_rgb_path, image_id_to_depth_path); times['v1'] = time.time() - start_time\n",
    "    ious['v1'] = calculate_iou(masks['v1'], target_gt_mask)\n",
    "    \n",
    "    # V2\n",
    "    start_time = time.time(); masks['v2'] = transfer_mask_v2(source_id, target_id, source_mask, component_name, images, cameras, image_id_to_rgb_path, image_id_to_depth_path); times['v2'] = time.time() - start_time\n",
    "    ious['v2'] = calculate_iou(masks['v2'], target_gt_mask)\n",
    "    \n",
    "    # V3\n",
    "    start_time = time.time(); masks['v3'] = transfer_mask_v3(source_id, target_id, source_mask, component_name, images, cameras, image_id_to_rgb_path, image_id_to_depth_path, image_id_to_mask_path); times['v3'] = time.time() - start_time\n",
    "    ious['v3'] = calculate_iou(masks['v3'], target_gt_mask)\n",
    "    \n",
    "    # --- NEW: V3_FAST ADDED HERE ---\n",
    "    start_time = time.time(); masks['v3_fast'] = transfer_mask_v3_fast(source_id, target_id, source_mask, component_name, images, cameras, image_id_to_rgb_path, image_id_to_depth_path, image_id_to_mask_path); times['v3_fast'] = time.time() - start_time\n",
    "    ious['v3_fast'] = calculate_iou(masks['v3_fast'], target_gt_mask)\n",
    "    \n",
    "    # V4\n",
    "    start_time = time.time(); masks['v4'] = transfer_mask_v4(source_id, target_id, source_mask, component_name, images, cameras, image_id_to_rgb_path, image_id_to_depth_path, image_id_to_mask_path); times['v4'] = time.time() - start_time\n",
    "    ious['v4'] = calculate_iou(masks['v4'], target_gt_mask)\n",
    "    \n",
    "    # V5\n",
    "    start_time = time.time(); masks['v5'] = transfer_mask_v5(source_id, target_id, source_mask, component_name, images, cameras, image_id_to_rgb_path, image_id_to_depth_path, image_id_to_mask_path); times['v5'] = time.time() - start_time\n",
    "    ious['v5'] = calculate_iou(masks['v5'], target_gt_mask)\n",
    "\n",
    "    # --- UPDATED LIST OF VERSIONS ---\n",
    "    versions_to_run = ['v1', 'v2', 'v3', 'v3_fast', 'v4', 'v5']\n",
    "\n",
    "    print(\"\\n--- Quantitative Results ---\")\n",
    "    for version in versions_to_run:\n",
    "        print(f\"  - {version.upper():<8}: Time = {times[version]:.2f}s | IoU = {ious[version]:.4f}\")\n",
    "\n",
    "    # --- Separate Visualization for Each Method ---\n",
    "    for version in versions_to_run:\n",
    "        fig, axes = plt.subplots(1, 3, figsize=(30, 10))\n",
    "        fig.suptitle(f\"Method {version.upper()} Comparison for '{component_name}'\", fontsize=24)\n",
    "\n",
    "        # Panel 1: Source\n",
    "        axes[0].imshow(source_rgb); axes[0].imshow(np.ma.masked_where(source_mask==0, source_mask), cmap='cool', alpha=0.6)\n",
    "        axes[0].set_title(\"1. Source Mask\", fontsize=18); axes[0].axis('off')\n",
    "\n",
    "        # Panel 2: Transferred Result\n",
    "        axes[1].imshow(target_rgb)\n",
    "        if masks[version] is not None:\n",
    "            overlay_res = target_rgb.copy(); roi_res = overlay_res[masks[version] > 0]; blended_res = (roi_res * 0.5 + np.array([0, 255, 0], dtype=np.uint8) * 0.5).astype(np.uint8); overlay_res[masks[version] > 0] = blended_res; axes[1].imshow(overlay_res)\n",
    "        axes[1].set_title(f\"2. {version.upper()} Result\\n(Time: {times[version]:.2f}s | IoU: {ious[version]:.4f})\", fontsize=18)\n",
    "        axes[1].axis('off')\n",
    "\n",
    "        # Panel 3: Ground Truth\n",
    "        axes[2].imshow(target_rgb); overlay_gt = target_rgb.copy(); roi_gt = overlay_gt[target_gt_mask > 0]; blended_gt = (roi_gt * 0.5 + np.array([255, 255, 0], dtype=np.uint8) * 0.5).astype(np.uint8); overlay_gt[target_gt_mask > 0] = blended_gt; axes[2].imshow(overlay_gt)\n",
    "        axes[2].set_title(\"3. Ground Truth Mask\", fontsize=18); axes[2].axis('off')\n",
    "\n",
    "        plt.tight_layout(rect=[0, 0, 1, 0.95])\n",
    "        plt.show()\n",
    "\n",
    "print(\"\\n\\nAll comparison examples are complete.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
